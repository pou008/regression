{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=left style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "Perceptron in ANN\n",
    "</font>\n",
    "</h2>\n",
    "    \n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "Perceptron is one of the main parts of learning phase in Artificial neural networks and we're going to using two methods for implementing it includes: 1- Perceptron, 2: Adaline\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from inspect import getsource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=left style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "DataSet\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "DataSet which being used is Iris flowers, which includes 3 kinds of flowers with each one 50 of them\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<center>\n",
    "<div dir=rtl style=\"direction: rtl;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    \n",
    "|Column|\n",
    "|:------:|\n",
    "|SepalLengthCm|\n",
    "|SepalWidthCm|\n",
    "|PetalLengthCm|\n",
    "|PetalWidthCm|\n",
    "|Species|\n",
    "</font>\n",
    "</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('iris.csv', usecols= lambda cols: cols != 'Id')\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=left style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "Feature Engineering\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "as one Perceptron can just predict in binary classify, we should split main df to three part\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = train_data[train_data['Species'].isin(['Iris-setosa', 'Iris-versicolor'])]\n",
    "\n",
    "df2 = train_data[train_data['Species'].isin(['Iris-setosa', 'Iris_virginica'])]\n",
    "\n",
    "df3 = train_data[train_data['Species'].isin(['Iris_virginica', 'Iris-versicolor'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[:, 'Species'] = df1['Species'].replace(['Iris-setosa', 'Iris-versicolor'], [1., -1.])\n",
    "df2.loc[:, 'Species'] = df2['Species'].replace(['Iris-setosa', 'Iris-virginica'], [1., -1.])\n",
    "df3.loc[:, 'Species'] = df3['Species'].replace(['Iris-versicolor', 'Iris-virginica'], [1., -1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df1 = df1['Species']\n",
    "df1.drop(columns= ['Species'], inplace= True)\n",
    "\n",
    "y_df2 = df2['Species']\n",
    "df2.drop(columns= ['Species'], inplace= True)\n",
    "\n",
    "y_df3 = df3['Species']\n",
    "df3.drop(columns= ['Species'], inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=left style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "Modeling\n",
    "</font>\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we want to implement a perceptron from zero without using sklearin lib using perceptron and delta rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron rule\n",
    "# this is based on stochastic gradient descent\n",
    "# Perceptron is used for linear separation\n",
    "\n",
    "class Perceptron:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.weights = None\n",
    "\n",
    "    def weighting(self, input):\n",
    "        \n",
    "        self.weights = np.random.rand(input.shape[0],)\n",
    "        return self.weights @ input.T\n",
    "\n",
    "    def activation(self, weighted_input):\n",
    "        return np.where(weighted_input >= 0, 1, -1)\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        inputs= inputs.copy()\n",
    "        inputs= pd.concat((pd.DataFrame(np.ones([len(inputs), 1])), inputs), axis= 1)\n",
    "        weighted_inputs = self.weighting(inputs)\n",
    "        return self.activation(weighted_inputs)\n",
    "\n",
    "    def fit(self, inputs, outputs, learning_rate, epochs):\n",
    "        inputs= inputs.copy()\n",
    "        inputs= pd.concat((pd.DataFrame(np.ones([len(inputs), 1])), inputs), axis= 1)\n",
    "        for i in range(epochs):\n",
    "            for sample_i in range(len(inputs)):\n",
    "                predicted_value = self.weighting(inputs.iloc[sample_i])\n",
    "                delta_w = learning_rate * (outputs.iloc[sample_i] - predicted_value) * inputs.iloc[sample_i].values\n",
    "                self.weights += delta_w\n",
    "                # print(self.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron = Perceptron()\n",
    "perceptron.fit(df1, y_df1, 0.1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adaline:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.weights = None\n",
    "\n",
    "    def weighting(self, input):\n",
    "        return self.weights @ input.T\n",
    "\n",
    "    def activation(self, weighted_input):\n",
    "        return weighted_input\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        inputs = np.insert(inputs, 0, [1], axis= 1)\n",
    "        weighted_array = self.weighting(inputs)\n",
    "        print(weighted_array)\n",
    "        activated_all = np.where(inputs >= 0, 1, -1)\n",
    "        return activated_all\n",
    "\n",
    "    def fit(self, inputs, outputs, learning_rate=0.1, epochs=64):\n",
    "        inputs = np.insert(inputs, 0, [1], axis= 1)\n",
    "        self.weights = np.random.rand(inputs.shape[1])\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            weighted_array = self.weighting(inputs)\n",
    "            diff = outputs - self.activation(weighted_array)\n",
    "            delta_w = self.weights * learning_rate * (diff.T @ inputs)\n",
    "            self.weights = self.weights + delta_w\n",
    "            # print(self.weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
